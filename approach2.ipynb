{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-07T07:23:59.951967900Z",
     "start_time": "2024-01-07T07:23:58.948918600Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('gigaword-nocase-26.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'suit', 'suited', 'suiting', 'suits'}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lemminflect import getAllInflections, getAllLemmas\n",
    "\n",
    "\n",
    "def get_inflections(word):\n",
    "    s = set()\n",
    "    try:\n",
    "        [s.add(y) for x in getAllInflections(list(getAllLemmas(word).values())[0][0]).values() for y in x]\n",
    "    except IndexError:\n",
    "        s.add(word)\n",
    "    return s\n",
    "\n",
    "\n",
    "get_inflections('suit')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T07:24:00.436338200Z",
     "start_time": "2024-01-07T07:24:00.429060900Z"
    }
   },
   "id": "e00bd946772583f6",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NishyBot2:\n",
    "    M = 2.5\n",
    "    TOP_N = int(M * 1000)\n",
    "    SAMENESS_THRESHOLD = 0\n",
    "    ALLOWED_POS = ['JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "    def find_similars(words):\n",
    "        similars = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                similars.append(\n",
    "                    {x[0]: i for i, x in enumerate(model.most_similar(positive=[word], topn=NishyBot2.TOP_N))})\n",
    "            except KeyError:\n",
    "                similars.append([])\n",
    "                print('No similar words found for', word)\n",
    "        return similars\n",
    "\n",
    "    def count_matches(wordlists, test):\n",
    "        count = 0\n",
    "        for wordlist in wordlists:\n",
    "            if test in wordlist:\n",
    "                count += NishyBot2.f(wordlist[test])\n",
    "        return count\n",
    "\n",
    "    def f(x):\n",
    "        k = NishyBot2.TOP_N\n",
    "        m = 10 ** NishyBot2.M\n",
    "        return k * (1 / (x + m) - 1 / (k + m)) / (1 / m - 1 / (k + m))\n",
    "\n",
    "    def __init__(self, good, bad, okay, assassin):\n",
    "        self.good = set()\n",
    "        self.bad = set()\n",
    "        self.okay = set()\n",
    "        self.assassin = set()\n",
    "\n",
    "        [self.good.add(inf) for word in good for inf in get_inflections(word)]\n",
    "        [self.bad.add(inf) for word in bad for inf in get_inflections(word)]\n",
    "        [self.okay.add(inf) for word in okay for inf in get_inflections(word)]\n",
    "        [self.assassin.add(inf) for word in assassin for inf in get_inflections(word)]\n",
    "\n",
    "        self.good = list(self.good)\n",
    "        self.bad = list(self.bad)\n",
    "        self.okay = list(self.okay)\n",
    "        self.assassin = list(self.assassin)\n",
    "        print(self.good)\n",
    "\n",
    "        self.good_similars = NishyBot2.find_similars(good)\n",
    "        self.bad_similars = NishyBot2.find_similars(bad)\n",
    "        self.okay_similars = NishyBot2.find_similars(okay)\n",
    "        self.assassin_similars = NishyBot2.find_similars(assassin)\n",
    "\n",
    "    def good_matches(self, test):\n",
    "        result = []\n",
    "        for i, similar in enumerate(self.good_similars):\n",
    "            if test in similar:\n",
    "                result.append(self.good[i])\n",
    "        return result\n",
    "\n",
    "    def score(self, test):\n",
    "        good_count = NishyBot2.count_matches(self.good_similars, test)\n",
    "        bad_count = NishyBot2.count_matches(self.bad_similars, test)\n",
    "        okay_count = NishyBot2.count_matches(self.okay_similars, test)\n",
    "        assassin_count = NishyBot2.count_matches(self.assassin_similars, test)\n",
    "\n",
    "        return good_count - bad_count - 0.5 * okay_count - 3 * assassin_count  # maybe use a gan to optimize these parameters + TOP_N? not many things to optimize...\n",
    "\n",
    "    def score_all(self, wordset):\n",
    "        scores = [(x, self.score(x)) for x in wordset]\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        scores = dict(scores)\n",
    "        return scores\n",
    "\n",
    "    def score_all_pruned(self, wordset):\n",
    "        scores = self.score_all(wordset)\n",
    "        hints = list(scores.keys())\n",
    "\n",
    "        for i, hint in enumerate(hints):\n",
    "            if len(wn.synsets(hint)) == 0:  # if it's not a real word\n",
    "                if hint in scores:\n",
    "                    scores.pop(hint)\n",
    "            elif pos_tag([hint])[0][1] not in NishyBot2.ALLOWED_POS:  # only allow nouns, adj, and verbs\n",
    "                if hint in scores:\n",
    "                    scores.pop(hint)\n",
    "            else:  # if it's too similar to an existing word\n",
    "                for word in self.good:\n",
    "                    if word in hint or hint in word:\n",
    "                        if hint in scores:\n",
    "                            scores.pop(hint)\n",
    "                            break\n",
    "\n",
    "        return scores\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T07:27:51.211480900Z",
     "start_time": "2024-01-07T07:27:51.199328400Z"
    }
   },
   "id": "15c8a61806e0e419",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pregame(good, bad, okay, assassin):\n",
    "    good2 = good.copy()\n",
    "    while len(good2) != 0:\n",
    "        n = NishyBot2(good2, bad, okay, assassin)\n",
    "\n",
    "        s = set()\n",
    "        for similar in n.good_similars:\n",
    "            for word in similar:\n",
    "                s.add(word)\n",
    "\n",
    "        sc = n.score_all_pruned(s)\n",
    "\n",
    "        hint = list(sc.keys())[0]\n",
    "        matches = n.good_matches(hint)\n",
    "        print(hint, matches)\n",
    "        good2 = list(filter(lambda x: x not in matches, good2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T07:27:52.002812800Z",
     "start_time": "2024-01-07T07:27:51.995779800Z"
    }
   },
   "id": "d3f7ac99c52a128c",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# good = 'sack makeup bottle cuckoo cast cone jockey America'.lower().split(' ')\n",
    "# bad = 'nut Russia fog break spider bear rip tube plane'.lower().split(' ')\n",
    "# okay = 'Christmas pool Beijing trip nyc fever peanut'.lower().split(' ')\n",
    "# assassin = 'link'.lower().split(' ')\n",
    "\n",
    "good = 'spot,blade,chain,record,magician,jeweler,fiddle,apple'.lower().split(',')\n",
    "bad = 'wonderland,Newton,glacier,pig,spy,lead,mess,duck,stable'.lower().split(',')\n",
    "okay = 'India,millionaire,rainbow,razor,bridge,polo,Notre,Dame'.lower().split(',')\n",
    "assassin = 'ice,cream'.lower().split(',')\n",
    "\n",
    "# good = ['giant', 'thumb', 'nail', 'lock','plane', 'ship','cell','state', 'capital']\n",
    "# bad = ['aztec', 'court','chocolate','space','snow']\n",
    "# okay = ['shop','genius','ambulance','button','heart','pupil','vet']\n",
    "# assassin = ['microscope']\n",
    "\n",
    "# good = 'apple,sister,river,einstein,brazil,garden,china,bench,tip'.split(',')\n",
    "# bad = 'ray,spider,king,arthur,rail,paste,cover,octopus'.split(',')\n",
    "# okay = 'roll,magazine,worm,bucket,golf,vacuum,scientist'.split(',')\n",
    "# assassin = ['code']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T07:27:52.259304300Z",
     "start_time": "2024-01-07T07:27:52.250294900Z"
    }
   },
   "id": "e4aee83445073875",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spying', 'stables', 'stabler', 'messes', 'stabling', 'glacier', 'stabled', 'spied', 'duck', 'mess', 'led', 'leads', 'pig', 'wonderland', 'glaciers', 'stable', 'ducking', 'spies', 'stablest', 'newtons', 'newton', 'lead', 'spy', 'ducks', 'pigs', 'messed', 'wonderlands', 'leading', 'ducked', 'messing']\n",
      "rabbit ['spying', 'messes', 'spied']\n",
      "['spying', 'stables', 'stabler', 'messes', 'stabling', 'glacier', 'stabled', 'spied', 'duck', 'mess', 'led', 'leads', 'pig', 'wonderland', 'glaciers', 'stable', 'ducking', 'spies', 'stablest', 'newtons', 'newton', 'lead', 'spy', 'ducks', 'pigs', 'messed', 'wonderlands', 'leading', 'ducked', 'messing']\n",
      "rabbit ['spying', 'messes', 'spied']\n",
      "['spying', 'stables', 'stabler', 'messes', 'stabling', 'glacier', 'stabled', 'spied', 'duck', 'mess', 'led', 'leads', 'pig', 'wonderland', 'glaciers', 'stable', 'ducking', 'spies', 'stablest', 'newtons', 'newton', 'lead', 'spy', 'ducks', 'pigs', 'messed', 'wonderlands', 'leading', 'ducked', 'messing']\n",
      "rabbit ['spying', 'messes', 'spied']\n",
      "['spying', 'stables', 'stabler', 'messes', 'stabling', 'glacier', 'stabled', 'spied', 'duck', 'mess', 'led', 'leads', 'pig', 'wonderland', 'glaciers', 'stable', 'ducking', 'spies', 'stablest', 'newtons', 'newton', 'lead', 'spy', 'ducks', 'pigs', 'messed', 'wonderlands', 'leading', 'ducked', 'messing']\n",
      "rabbit ['spying', 'messes', 'spied']\n",
      "['spying', 'stables', 'stabler', 'messes', 'stabling', 'glacier', 'stabled', 'spied', 'duck', 'mess', 'led', 'leads', 'pig', 'wonderland', 'glaciers', 'stable', 'ducking', 'spies', 'stablest', 'newtons', 'newton', 'lead', 'spy', 'ducks', 'pigs', 'messed', 'wonderlands', 'leading', 'ducked', 'messing']\n",
      "rabbit ['spying', 'messes', 'spied']\n",
      "['spying', 'stables', 'stabler', 'messes', 'stabling', 'glacier', 'stabled', 'spied', 'duck', 'mess', 'led', 'leads', 'pig', 'wonderland', 'glaciers', 'stable', 'ducking', 'spies', 'stablest', 'newtons', 'newton', 'lead', 'spy', 'ducks', 'pigs', 'messed', 'wonderlands', 'leading', 'ducked', 'messing']\n",
      "rabbit ['spying', 'messes', 'spied']\n",
      "['spying', 'stables', 'stabler', 'messes', 'stabling', 'glacier', 'stabled', 'spied', 'duck', 'mess', 'led', 'leads', 'pig', 'wonderland', 'glaciers', 'stable', 'ducking', 'spies', 'stablest', 'newtons', 'newton', 'lead', 'spy', 'ducks', 'pigs', 'messed', 'wonderlands', 'leading', 'ducked', 'messing']\n",
      "rabbit ['spying', 'messes', 'spied']\n",
      "['spying', 'stables', 'stabler', 'messes', 'stabling', 'glacier', 'stabled', 'spied', 'duck', 'mess', 'led', 'leads', 'pig', 'wonderland', 'glaciers', 'stable', 'ducking', 'spies', 'stablest', 'newtons', 'newton', 'lead', 'spy', 'ducks', 'pigs', 'messed', 'wonderlands', 'leading', 'ducked', 'messing']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpregame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgood\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mokay\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43massassin\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[47], line 11\u001B[0m, in \u001B[0;36mpregame\u001B[1;34m(good, bad, okay, assassin)\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m similar:\n\u001B[0;32m      9\u001B[0m         s\u001B[38;5;241m.\u001B[39madd(word)\n\u001B[1;32m---> 11\u001B[0m sc \u001B[38;5;241m=\u001B[39m \u001B[43mn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore_all_pruned\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m hint \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(sc\u001B[38;5;241m.\u001B[39mkeys())[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     14\u001B[0m matches \u001B[38;5;241m=\u001B[39m n\u001B[38;5;241m.\u001B[39mgood_matches(hint)\n",
      "Cell \u001B[1;32mIn[46], line 81\u001B[0m, in \u001B[0;36mNishyBot2.score_all_pruned\u001B[1;34m(self, wordset)\u001B[0m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hint \u001B[38;5;129;01min\u001B[39;00m scores:\n\u001B[0;32m     80\u001B[0m         scores\u001B[38;5;241m.\u001B[39mpop(hint)\n\u001B[1;32m---> 81\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[43mpos_tag\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mhint\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m NishyBot2\u001B[38;5;241m.\u001B[39mALLOWED_POS:  \u001B[38;5;66;03m# only allow nouns, adj, and verbs\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hint \u001B[38;5;129;01min\u001B[39;00m scores:\n\u001B[0;32m     83\u001B[0m         scores\u001B[38;5;241m.\u001B[39mpop(hint)\n",
      "File \u001B[1;32m~\\IdeaProjects\\codenames\\env\\Lib\\site-packages\\nltk\\tag\\__init__.py:165\u001B[0m, in \u001B[0;36mpos_tag\u001B[1;34m(tokens, tagset, lang)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpos_tag\u001B[39m(tokens, tagset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, lang\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meng\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    141\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;124;03m    tag the given list of tokens.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;124;03m    :rtype: list(tuple(str, str))\u001B[39;00m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 165\u001B[0m     tagger \u001B[38;5;241m=\u001B[39m \u001B[43m_get_tagger\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlang\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001B[1;32m~\\IdeaProjects\\codenames\\env\\Lib\\site-packages\\nltk\\tag\\__init__.py:107\u001B[0m, in \u001B[0;36m_get_tagger\u001B[1;34m(lang)\u001B[0m\n\u001B[0;32m    105\u001B[0m     tagger\u001B[38;5;241m.\u001B[39mload(ap_russian_model_loc)\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 107\u001B[0m     tagger \u001B[38;5;241m=\u001B[39m \u001B[43mPerceptronTagger\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tagger\n",
      "File \u001B[1;32m~\\IdeaProjects\\codenames\\env\\Lib\\site-packages\\nltk\\tag\\perceptron.py:167\u001B[0m, in \u001B[0;36mPerceptronTagger.__init__\u001B[1;34m(self, load)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m load:\n\u001B[0;32m    166\u001B[0m     AP_MODEL_LOC \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\n\u001B[1;32m--> 167\u001B[0m         \u001B[43mfind\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtaggers/averaged_perceptron_tagger/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mPICKLE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m     )\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload(AP_MODEL_LOC)\n",
      "File \u001B[1;32m~\\IdeaProjects\\codenames\\env\\Lib\\site-packages\\nltk\\data.py:537\u001B[0m, in \u001B[0;36mfind\u001B[1;34m(resource_name, paths)\u001B[0m\n\u001B[0;32m    535\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m GzipFileSystemPathPointer(p)\n\u001B[0;32m    536\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 537\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFileSystemPathPointer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    539\u001B[0m     p \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path_, url2pathname(zipfile))\n",
      "File \u001B[1;32m~\\IdeaProjects\\codenames\\env\\Lib\\site-packages\\nltk\\compat.py:41\u001B[0m, in \u001B[0;36mpy3_data.<locals>._decorator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_decorator\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     40\u001B[0m     args \u001B[38;5;241m=\u001B[39m (args[\u001B[38;5;241m0\u001B[39m], add_py3_data(args[\u001B[38;5;241m1\u001B[39m])) \u001B[38;5;241m+\u001B[39m args[\u001B[38;5;241m2\u001B[39m:]\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minit_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\IdeaProjects\\codenames\\env\\Lib\\site-packages\\nltk\\data.py:311\u001B[0m, in \u001B[0;36mFileSystemPathPointer.__init__\u001B[1;34m(self, _path)\u001B[0m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;124;03mCreate a new path pointer for the given absolute path.\u001B[39;00m\n\u001B[0;32m    306\u001B[0m \n\u001B[0;32m    307\u001B[0m \u001B[38;5;124;03m:raise IOError: If the given path does not exist.\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    310\u001B[0m _path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(_path)\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexists\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_path\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo such file or directory: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m _path)\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_path \u001B[38;5;241m=\u001B[39m _path\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pregame(bad, good, okay, assassin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T07:28:09.557615300Z",
     "start_time": "2024-01-07T07:27:52.781684100Z"
    }
   },
   "id": "58a06603cade8335",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apples', 'jewelers', 'blades', 'chains', 'magicians', 'apple', 'recording', 'chain', 'fiddling', 'spots', 'chained', 'spotting', 'chaining', 'jeweler', 'fiddles', 'magician', 'record', 'blade', 'records', 'fiddled', 'recorded', 'spotted', 'spot', 'fiddle']\n",
      "17203\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('virtuoso', ['magicians', 'recording'], 4668.760239467705),\n ('store', ['blades', 'apple', 'chain'], 4636.48823258486),\n ('violinist', ['magicians', 'apple', 'recording'], 4295.664819241085),\n ('retailer', ['blades', 'apple', 'chain'], 4272.45588289574),\n ('boutique', ['blades', 'apple'], 4109.424182754109),\n ('shop', ['blades', 'apple'], 3869.938982017129),\n ('mandolin', ['jewelers', 'recording'], 3745.6366486038537),\n ('restaurant', ['apples', 'blades', 'apple'], 3695.8342998441235),\n ('musician', ['magicians', 'apple', 'recording'], 3668.2807781043725),\n ('painter', ['magicians', 'apple'], 3644.908281142476),\n ('supermarket', ['blades', 'apple'], 3550.6047708071683),\n ('jewelry', ['blades', 'apple'], 3481.106043274222),\n ('pianist', ['magicians', 'apple', 'recording'], 3432.402181638563),\n ('grocer', ['blades', 'apple', 'chain'], 3424.2547642956906),\n ('percussionist', ['magicians', 'recording'], 3394.390372353384),\n ('maestro', ['magicians', 'recording'], 3391.748371398058),\n ('lead', ['apples', 'chains'], 3283.006318246701),\n ('mime', ['magicians', 'recording'], 3277.0005121710255),\n ('sculptor', ['magicians', 'apple'], 3199.6469752886724),\n ('grocery', ['blades', 'apple'], 3187.6742978984093)]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = NishyBot2(good, bad, okay, assassin)\n",
    "\n",
    "s = set()\n",
    "for similar in n.good_similars:\n",
    "    for word in similar:\n",
    "        s.add(word)\n",
    "print(len(s))\n",
    "\n",
    "sc = n.score_all_pruned(s)\n",
    "[(x, n.good_matches(x), sc[x]) for x in list(sc.keys())][:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T07:29:01.073119100Z",
     "start_time": "2024-01-07T07:28:58.767830800Z"
    }
   },
   "id": "6e0e101fca9f0ee0",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "set()"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = set()\n",
    "for similar in n.good_similars:\n",
    "    for word in similar:\n",
    "        s.add(word)\n",
    "\n",
    "set(n.good_similars[1].keys()).intersection(set(n.good_similars[2].keys())).intersection(set(n.good_similars[8].keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T09:13:41.063194700Z",
     "start_time": "2024-01-04T09:13:41.057672500Z"
    }
   },
   "id": "b5e4859b13ae9d96",
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "india ['brazil', 'china']\n",
      "tributary ['river']\n",
      "dugout ['bench']\n",
      "lawn ['garden']\n",
      "corner ['tip']\n",
      "brother ['sister']\n",
      "relativity ['einstein']\n",
      "ipod ['apple']\n",
      "\n",
      "500\n",
      "india ['brazil', 'china']\n",
      "substitute ['bench', 'tip']\n",
      "pond ['river', 'garden']\n",
      "sibling ['sister']\n",
      "relativity ['einstein']\n",
      "ipod ['apple']\n",
      "\n",
      "1000\n",
      "india ['brazil', 'china']\n",
      "substitute ['bench', 'tip']\n",
      "terrace ['river', 'garden']\n",
      "sibling ['sister']\n",
      "relativity ['einstein']\n",
      "ipod ['apple']\n",
      "\n",
      "2000\n",
      "india ['brazil', 'china']\n",
      "substitute ['bench', 'tip']\n",
      "lake ['river', 'garden']\n",
      "relativity ['einstein']\n",
      "sibling ['sister']\n",
      "ipod ['apple']\n",
      "\n",
      "3000\n",
      "india ['brazil', 'china']\n",
      "substitute ['bench', 'tip']\n",
      "lake ['river', 'garden']\n",
      "relativity ['einstein']\n",
      "sibling ['sister']\n",
      "ipod ['apple']\n",
      "\n",
      "5000\n",
      "india ['brazil', 'china']\n",
      "substitute ['bench', 'tip']\n",
      "terrace ['river', 'garden']\n",
      "freud ['einstein']\n",
      "sibling ['sister']\n",
      "ipod ['apple']\n"
     ]
    }
   ],
   "source": [
    "ns = [100, 500, 1000, 2000, 3000, 5000]\n",
    "for n in ns:\n",
    "    print(n)\n",
    "    NishyBot2.TOP_N = n\n",
    "    pregame(good, bad, okay, assassin)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T09:14:09.984852400Z",
     "start_time": "2024-01-04T09:13:41.062191900Z"
    }
   },
   "id": "36c197a22473ed44",
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NishyBot2.count_matches(n.bad_similars, 'spoiled')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e1607b5e74a93b",
   "execution_count": 224
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.good_similars[good.index('cone')].index('encase')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T10:01:53.697365Z",
     "start_time": "2023-12-31T10:01:53.691761600Z"
    }
   },
   "id": "b4fcb10ec4c83799",
   "execution_count": 227
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('possibly', 'RB')]"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "\n",
    "pos_tag(['possibly'\n",
    "         ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T09:10:15.452136500Z",
     "start_time": "2024-01-04T09:10:15.446220100Z"
    }
   },
   "id": "c774ccd1ddd24926",
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f1e2d0c43c9fc083"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
